{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e356054a",
   "metadata": {},
   "source": [
    "# EX 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c7f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jojol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jojol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d907133",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "\n",
    "\n",
    "booklists = os.listdir(\"Data - Copy/\")\n",
    "\n",
    "totalwording=[]\n",
    "listbook=[]\n",
    "\n",
    "for book in booklists:\n",
    "    cleanbook=book.replace(\".txt\",\"\")\n",
    "    listbook.append(cleanbook)\n",
    "    \n",
    "    text = open('Data - Copy/'+book, mode=\"r\",encoding=\"UTF-8\").read()\n",
    "    \n",
    "    Alice_blank = blankline_tokenize(text)\n",
    "    \n",
    "\n",
    "    i = \"\"\n",
    "\n",
    "    j = \"\"\n",
    "    match = [\"START\", \"***\", \"GUTENBERG\"]\n",
    "    for i in range(len(Alice_blank)):\n",
    "        if all(x in Alice_blank[i] for x in match):\n",
    "            i = i+2\n",
    "            break\n",
    "\n",
    "    matches = [\"END\", \"***\", \"GUTENBERG\"]\n",
    "    for j in range(len(Alice_blank)):\n",
    "        if all(x in Alice_blank[j] for x in matches):\n",
    "            j = j-1\n",
    "            break\n",
    "\n",
    "    Alices='\\n'.join(Alice_blank[i:j])\n",
    "    Alices=Alices.replace(\"_\",\" \")\n",
    "    Alices=Alices.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    Alices=Alices.lower()\n",
    "\n",
    "    text_clean=Alices.replace(\"─\",\" \")\n",
    "    text_clean=text_clean.replace(\"┼\",\" \")\n",
    "    text_clean=text_clean.replace(\"┬\",\" \")\n",
    "    text_clean=text_clean.replace(\"┴\",\" \")\n",
    "    text_clean=text_clean.replace(\"│\",\" \")\n",
    "    text_nonum = re.sub(r'\\d+', ' ', text_clean)\n",
    "\n",
    "\n",
    "    wordings = text_nonum.split()\n",
    "    stop_words = list(get_stop_words('en'))  \n",
    "    stopwords= ['.', ',', \"'\", 'E', 'u','S', \"n't\",\"ll\",\"re\",\"gutenberg\",\"gutenbergtm\",\"much\"] + list(STOPWORDS)+stop_words\n",
    "\n",
    "\n",
    "    post_stop = [word for word in wordings if not word in stopwords]\n",
    "\n",
    "\n",
    "    punctuation = re.compile(r'!\"#$%&()*,-./:;<=>?[\\]^_`{|}~[0-9]')\n",
    "\n",
    "    post_punctuation = []\n",
    "    for words in post_stop:\n",
    "        word = punctuation.sub(\"\", words)\n",
    "        if len(word) > 3:\n",
    "            post_punctuation.append(word)\n",
    "\n",
    "    word_lem = WordNetLemmatizer()\n",
    "\n",
    "    removepunc = str.maketrans('', '', string.punctuation)\n",
    "    strippedpunc = [w.translate(removepunc) for w in post_punctuation]\n",
    "    strippedpunc\n",
    "\n",
    "    lemmatizetxt=[]\n",
    "\n",
    "    for words in strippedpunc:\n",
    "        lemmatizetxt.append(word_lem.lemmatize(words))\n",
    "\n",
    "    resultz = pos_tag(lemmatizetxt)\n",
    "    ResultFin=[s for s in resultz if s[1] != 'WP' and s[1] != 'WTD'and s[1] != 'WDT' and s[1] != 'IN'and s[1] != 'PRP' and s[1] != 'PRP$'  and s[1] != 'DT' and s[1] != 'CD']\n",
    "    resulfinal=[x for (x,y) in ResultFin]\n",
    "\n",
    "\n",
    "    new_lemmatizetxt = [item for item in resulfinal if not item.isdigit()]\n",
    "    \n",
    "    wt_words = new_lemmatizetxt\n",
    "    \n",
    "    data_analysis = nltk.FreqDist(wt_words)\n",
    " \n",
    "    filter_words = dict([(m, n) for m, n in data_analysis.items() if len(m) > 3])\n",
    "    \n",
    "\n",
    "\n",
    "    fdist_top100 = FreqDist(filter_words).most_common(100)\n",
    "    \n",
    "    Resultfine=[]\n",
    "    for key,value in sorted(fdist_top100):\n",
    "        totalwording.append(key)\n",
    "        \n",
    "    Result=[]\n",
    "    for key, value in fdist_top100:\n",
    "        Result.append(((key+\",\")*value))\n",
    "    remi=\"\".join(Result)\n",
    "    corpus.append(remi)\n",
    "  \n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(totalwording )\n",
    "ligne=vectorizer.get_feature_names()\n",
    "colonne=listbook\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60e64df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice-in-wonderland</th>\n",
       "      <th>Among the Forest People</th>\n",
       "      <th>An Introductory Course of Quantitative Chemical Analysis</th>\n",
       "      <th>Curious Myths of the Middle Ages</th>\n",
       "      <th>Democracy In America, Volume 1 (of 2)</th>\n",
       "      <th>Experiments and Observations on Different</th>\n",
       "      <th>Formation of the Union, 1750-1829</th>\n",
       "      <th>Histories of two hundred and fifty-one divisions of the German army which participated in the wa</th>\n",
       "      <th>History of King Charles The First of England</th>\n",
       "      <th>History of Phosphorus</th>\n",
       "      <th>...</th>\n",
       "      <th>The Tale of Timmy Tiptoes</th>\n",
       "      <th>The Threefold Commonwealth</th>\n",
       "      <th>The Toxicity of Caffein An experimental study on different species of animals</th>\n",
       "      <th>The United States of America Part I</th>\n",
       "      <th>The White Feather</th>\n",
       "      <th>Three Minute Stories</th>\n",
       "      <th>Through the Looking-Glass</th>\n",
       "      <th>Tiger and Tom and Other Stories for Boys</th>\n",
       "      <th>Tom Sawyer Abroad</th>\n",
       "      <th>War and Peace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absorbed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abysmal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abyss</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeitschr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1771 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          alice-in-wonderland  Among the Forest People  \\\n",
       "ability                   0.0                  0.00000   \n",
       "able                      0.0                  0.00000   \n",
       "absorbed                  0.0                  0.00000   \n",
       "abysmal                   0.0                  0.00000   \n",
       "abyss                     0.0                  0.00000   \n",
       "...                       ...                      ...   \n",
       "young                     0.0                  0.14665   \n",
       "youth                     0.0                  0.00000   \n",
       "zeitschr                  0.0                  0.00000   \n",
       "zinc                      0.0                  0.00000   \n",
       "zone                      0.0                  0.00000   \n",
       "\n",
       "          An Introductory Course of Quantitative Chemical Analysis  \\\n",
       "ability                                                 0.0          \n",
       "able                                                    0.0          \n",
       "absorbed                                                0.0          \n",
       "abysmal                                                 0.0          \n",
       "abyss                                                   0.0          \n",
       "...                                                     ...          \n",
       "young                                                   0.0          \n",
       "youth                                                   0.0          \n",
       "zeitschr                                                0.0          \n",
       "zinc                                                    0.0          \n",
       "zone                                                    0.0          \n",
       "\n",
       "          Curious Myths of the Middle Ages  \\\n",
       "ability                                0.0   \n",
       "able                                   0.0   \n",
       "absorbed                               0.0   \n",
       "abysmal                                0.0   \n",
       "abyss                                  0.0   \n",
       "...                                    ...   \n",
       "young                                  0.0   \n",
       "youth                                  0.0   \n",
       "zeitschr                               0.0   \n",
       "zinc                                   0.0   \n",
       "zone                                   0.0   \n",
       "\n",
       "          Democracy In America, Volume 1 (of 2)  \\\n",
       "ability                                     0.0   \n",
       "able                                        0.0   \n",
       "absorbed                                    0.0   \n",
       "abysmal                                     0.0   \n",
       "abyss                                       0.0   \n",
       "...                                         ...   \n",
       "young                                       0.0   \n",
       "youth                                       0.0   \n",
       "zeitschr                                    0.0   \n",
       "zinc                                        0.0   \n",
       "zone                                        0.0   \n",
       "\n",
       "          Experiments and Observations on Different  \\\n",
       "ability                                    0.000000   \n",
       "able                                       0.000000   \n",
       "absorbed                                   0.083039   \n",
       "abysmal                                    0.000000   \n",
       "abyss                                      0.000000   \n",
       "...                                             ...   \n",
       "young                                      0.000000   \n",
       "youth                                      0.000000   \n",
       "zeitschr                                   0.000000   \n",
       "zinc                                       0.000000   \n",
       "zone                                       0.000000   \n",
       "\n",
       "          Formation of the Union, 1750-1829  \\\n",
       "ability                                 0.0   \n",
       "able                                    0.0   \n",
       "absorbed                                0.0   \n",
       "abysmal                                 0.0   \n",
       "abyss                                   0.0   \n",
       "...                                     ...   \n",
       "young                                   0.0   \n",
       "youth                                   0.0   \n",
       "zeitschr                                0.0   \n",
       "zinc                                    0.0   \n",
       "zone                                    0.0   \n",
       "\n",
       "          Histories of two hundred and fifty-one divisions of the German army which participated in the wa  \\\n",
       "ability                                                 0.0                                                  \n",
       "able                                                    0.0                                                  \n",
       "absorbed                                                0.0                                                  \n",
       "abysmal                                                 0.0                                                  \n",
       "abyss                                                   0.0                                                  \n",
       "...                                                     ...                                                  \n",
       "young                                                   0.0                                                  \n",
       "youth                                                   0.0                                                  \n",
       "zeitschr                                                0.0                                                  \n",
       "zinc                                                    0.0                                                  \n",
       "zone                                                    0.0                                                  \n",
       "\n",
       "          History of King Charles The First of England  History of Phosphorus  \\\n",
       "ability                                            0.0                    0.0   \n",
       "able                                               0.0                    0.0   \n",
       "absorbed                                           0.0                    0.0   \n",
       "abysmal                                            0.0                    0.0   \n",
       "abyss                                              0.0                    0.0   \n",
       "...                                                ...                    ...   \n",
       "young                                              0.0                    0.0   \n",
       "youth                                              0.0                    0.0   \n",
       "zeitschr                                           0.0                    0.0   \n",
       "zinc                                               0.0                    0.0   \n",
       "zone                                               0.0                    0.0   \n",
       "\n",
       "          ...  The Tale of Timmy Tiptoes  The Threefold Commonwealth  \\\n",
       "ability   ...                        0.0                    0.085148   \n",
       "able      ...                        0.0                    0.054439   \n",
       "absorbed  ...                        0.0                    0.000000   \n",
       "abysmal   ...                        0.0                    0.000000   \n",
       "abyss     ...                        0.0                    0.000000   \n",
       "...       ...                        ...                         ...   \n",
       "young     ...                        0.0                    0.000000   \n",
       "youth     ...                        0.0                    0.000000   \n",
       "zeitschr  ...                        0.0                    0.000000   \n",
       "zinc      ...                        0.0                    0.000000   \n",
       "zone      ...                        0.0                    0.000000   \n",
       "\n",
       "          The Toxicity of Caffein An experimental study on different species of animals  \\\n",
       "ability                                                 0.0                               \n",
       "able                                                    0.0                               \n",
       "absorbed                                                0.0                               \n",
       "abysmal                                                 0.0                               \n",
       "abyss                                                   0.0                               \n",
       "...                                                     ...                               \n",
       "young                                                   0.0                               \n",
       "youth                                                   0.0                               \n",
       "zeitschr                                                0.0                               \n",
       "zinc                                                    0.0                               \n",
       "zone                                                    0.0                               \n",
       "\n",
       "          The United States of America Part I  The White Feather  \\\n",
       "ability                                   0.0                0.0   \n",
       "able                                      0.0                0.0   \n",
       "absorbed                                  0.0                0.0   \n",
       "abysmal                                   0.0                0.0   \n",
       "abyss                                     0.0                0.0   \n",
       "...                                       ...                ...   \n",
       "young                                     0.0                0.0   \n",
       "youth                                     0.0                0.0   \n",
       "zeitschr                                  0.0                0.0   \n",
       "zinc                                      0.0                0.0   \n",
       "zone                                      0.0                0.0   \n",
       "\n",
       "          Three Minute Stories  Through the Looking-Glass  \\\n",
       "ability                    0.0                        0.0   \n",
       "able                       0.0                        0.0   \n",
       "absorbed                   0.0                        0.0   \n",
       "abysmal                    0.0                        0.0   \n",
       "abyss                      0.0                        0.0   \n",
       "...                        ...                        ...   \n",
       "young                      0.0                        0.0   \n",
       "youth                      0.0                        0.0   \n",
       "zeitschr                   0.0                        0.0   \n",
       "zinc                       0.0                        0.0   \n",
       "zone                       0.0                        0.0   \n",
       "\n",
       "          Tiger and Tom and Other Stories for Boys  Tom Sawyer Abroad  \\\n",
       "ability                                   0.000000                0.0   \n",
       "able                                      0.000000                0.0   \n",
       "absorbed                                  0.000000                0.0   \n",
       "abysmal                                   0.000000                0.0   \n",
       "abyss                                     0.000000                0.0   \n",
       "...                                            ...                ...   \n",
       "young                                     0.124921                0.0   \n",
       "youth                                     0.000000                0.0   \n",
       "zeitschr                                  0.000000                0.0   \n",
       "zinc                                      0.000000                0.0   \n",
       "zone                                      0.000000                0.0   \n",
       "\n",
       "          War and Peace  \n",
       "ability        0.000000  \n",
       "able           0.000000  \n",
       "absorbed       0.000000  \n",
       "abysmal        0.000000  \n",
       "abyss          0.000000  \n",
       "...                 ...  \n",
       "young          0.057731  \n",
       "youth          0.000000  \n",
       "zeitschr       0.000000  \n",
       "zinc           0.000000  \n",
       "zone           0.000000  \n",
       "\n",
       "[1771 rows x 52 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "df = pd.DataFrame(data=X.todense(), columns=vectorizer.get_feature_names())\n",
    "df_t=df.T\n",
    "df_t\n",
    "df_t.columns=colonne\n",
    "df_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1137a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 99 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 99 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 99 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 99 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 93 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 99 stored elements in Compressed Sparse Row format>, <1x1771 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 100 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "print(list(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301d50b",
   "metadata": {},
   "source": [
    "# EX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ba02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106c823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:  ['said', 'little', 'king', 'will', 'time', 'know', 'mother', 'came', 'great', 'come']\n",
      "Topic 1:  ['state', 'government', 'american', 'united', 'power', 'sidenote', 'country', 'congress', 'general', 'national']\n",
      "Topic 2:  ['acid', 'water', 'solution', 'food', 'experiment', 'soap', 'animal', 'quantity', 'temperature', 'weight']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'absorbed',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'acetate',\n",
       " 'acid',\n",
       " 'acidity',\n",
       " 'action',\n",
       " 'actual',\n",
       " 'adam',\n",
       " 'adapted',\n",
       " 'added',\n",
       " 'addition',\n",
       " 'administered',\n",
       " 'administration',\n",
       " 'advantage',\n",
       " 'affair',\n",
       " 'afraid',\n",
       " 'again',\n",
       " 'agitation',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'albert',\n",
       " 'albumen',\n",
       " 'alcohol',\n",
       " 'aldershot',\n",
       " 'alexandra',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alive',\n",
       " 'alkali',\n",
       " 'alkaline',\n",
       " 'allardyce',\n",
       " 'allotment',\n",
       " 'allowed',\n",
       " 'almost',\n",
       " 'along',\n",
       " 'alphonso',\n",
       " 'already',\n",
       " 'always',\n",
       " 'ambassador',\n",
       " 'ambulance',\n",
       " 'amedee',\n",
       " 'amer',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ammonia',\n",
       " 'ammonium',\n",
       " 'amount',\n",
       " 'analogy',\n",
       " 'analysis',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'angelica',\n",
       " 'anhydrous',\n",
       " 'animal',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'antichrist',\n",
       " 'antimony',\n",
       " 'antiq',\n",
       " 'antiquity',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appetite',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'appointed',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'archbishop',\n",
       " 'area',\n",
       " 'argon',\n",
       " 'argument',\n",
       " 'army',\n",
       " 'arrow',\n",
       " 'arsenic',\n",
       " 'arthur',\n",
       " 'article',\n",
       " 'artillery',\n",
       " 'asked',\n",
       " 'assembly',\n",
       " 'atmosphere',\n",
       " 'atom',\n",
       " 'atomic',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attell',\n",
       " 'august',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'autopsy',\n",
       " 'average',\n",
       " 'avge',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'aymar',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bagful',\n",
       " 'balance',\n",
       " 'balloon',\n",
       " 'bancroft',\n",
       " 'bank',\n",
       " 'banner',\n",
       " 'barbarian',\n",
       " 'barium',\n",
       " 'battalion',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bavarian',\n",
       " 'bead',\n",
       " 'beaker',\n",
       " 'beast',\n",
       " 'beatrix',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begun',\n",
       " 'behaviour',\n",
       " 'being',\n",
       " 'belgian',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'benson',\n",
       " 'bergson',\n",
       " 'bert',\n",
       " 'best',\n",
       " 'betsinda',\n",
       " 'betson',\n",
       " 'better',\n",
       " 'bevan',\n",
       " 'bible',\n",
       " 'bill',\n",
       " 'binding',\n",
       " 'biological',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'bishop',\n",
       " 'bismuth',\n",
       " 'black',\n",
       " 'blackstick',\n",
       " 'blood',\n",
       " 'blowpipe',\n",
       " 'blue',\n",
       " 'boat',\n",
       " 'bobbie',\n",
       " 'bodo',\n",
       " 'body',\n",
       " 'boil',\n",
       " 'boiled',\n",
       " 'boiling',\n",
       " 'bonaparte',\n",
       " 'bone',\n",
       " 'book',\n",
       " 'boot',\n",
       " 'borax',\n",
       " 'born',\n",
       " 'bottom',\n",
       " 'bourgeois',\n",
       " 'bourgeoisie',\n",
       " 'boxing',\n",
       " 'branch',\n",
       " 'brave',\n",
       " 'bread',\n",
       " 'breed',\n",
       " 'brig',\n",
       " 'brigade',\n",
       " 'bright',\n",
       " 'brimstone',\n",
       " 'brindle',\n",
       " 'bring',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'brittle',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'bruce',\n",
       " 'bruised',\n",
       " 'btries',\n",
       " 'buckingham',\n",
       " 'bulbo',\n",
       " 'bulletin',\n",
       " 'bunsen',\n",
       " 'burette',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burrow',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butter',\n",
       " 'butterfly',\n",
       " 'cabin',\n",
       " 'caffein',\n",
       " 'calais',\n",
       " 'calcium',\n",
       " 'calculate',\n",
       " 'calculated',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calx',\n",
       " 'cambrai',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'can',\n",
       " 'candle',\n",
       " 'capital',\n",
       " 'capn',\n",
       " 'captain',\n",
       " 'captured',\n",
       " 'carbon',\n",
       " 'carbonate',\n",
       " 'care',\n",
       " 'carl',\n",
       " 'carman',\n",
       " 'carnivorous',\n",
       " 'carolina',\n",
       " 'carpet',\n",
       " 'carriage',\n",
       " 'carroll',\n",
       " 'carrot',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'casein',\n",
       " 'castle',\n",
       " 'catalogue',\n",
       " 'caterpillar',\n",
       " 'catholic',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caustic',\n",
       " 'cavalry',\n",
       " 'cavendish',\n",
       " 'cavity',\n",
       " 'cedric',\n",
       " 'cell',\n",
       " 'cent',\n",
       " 'centimeter',\n",
       " 'central',\n",
       " 'century',\n",
       " 'certain',\n",
       " 'certainpersonio',\n",
       " 'chair',\n",
       " 'challenger',\n",
       " 'champagne',\n",
       " 'changarnier',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'chap',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'characteristic',\n",
       " 'charcoal',\n",
       " 'charge',\n",
       " 'charles',\n",
       " 'chaucer',\n",
       " 'cheer',\n",
       " 'cheese',\n",
       " 'chem',\n",
       " 'chemical',\n",
       " 'chemistry',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'chipmunk',\n",
       " 'chippy',\n",
       " 'chloride',\n",
       " 'choline',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christmas',\n",
       " 'chromium',\n",
       " 'chuckled',\n",
       " 'church',\n",
       " 'circumstance',\n",
       " 'citizen',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'class',\n",
       " 'clearing',\n",
       " 'clever',\n",
       " 'close',\n",
       " 'cloth',\n",
       " 'clothes',\n",
       " 'coal',\n",
       " 'coarse',\n",
       " 'coast',\n",
       " 'coating',\n",
       " 'cobalt',\n",
       " 'cocoanut',\n",
       " 'coggeshall',\n",
       " 'cold',\n",
       " 'colin',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'colonial',\n",
       " 'colony',\n",
       " 'color',\n",
       " 'colorless',\n",
       " 'colour',\n",
       " 'colourplate',\n",
       " 'combination',\n",
       " 'combustion',\n",
       " 'come',\n",
       " 'command',\n",
       " 'commander',\n",
       " 'commerce',\n",
       " 'commodity',\n",
       " 'common',\n",
       " 'community',\n",
       " 'company',\n",
       " 'competition',\n",
       " 'complete',\n",
       " 'component',\n",
       " 'composition',\n",
       " 'compound',\n",
       " 'concentration',\n",
       " 'conception',\n",
       " 'conclusion',\n",
       " 'condition',\n",
       " 'confederate',\n",
       " 'congested',\n",
       " 'congress',\n",
       " 'cono',\n",
       " 'conquer',\n",
       " 'conquered',\n",
       " 'conquest',\n",
       " 'consequence',\n",
       " 'considerable',\n",
       " 'considered',\n",
       " 'constant',\n",
       " 'constantine',\n",
       " 'constantinople',\n",
       " 'constellation',\n",
       " 'constituent',\n",
       " 'constitution',\n",
       " 'constitutional',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'content',\n",
       " 'continent',\n",
       " 'continued',\n",
       " 'convention',\n",
       " 'convulsion',\n",
       " 'cooh',\n",
       " 'cook',\n",
       " 'cooked',\n",
       " 'cookery',\n",
       " 'cooking',\n",
       " 'coon',\n",
       " 'copper',\n",
       " 'copy',\n",
       " 'cori',\n",
       " 'corner',\n",
       " 'corp',\n",
       " 'couldn',\n",
       " 'council',\n",
       " 'count',\n",
       " 'countess',\n",
       " 'country',\n",
       " 'course',\n",
       " 'court',\n",
       " 'covered',\n",
       " 'cowardly',\n",
       " 'craven',\n",
       " 'creature',\n",
       " 'cricket',\n",
       " 'cried',\n",
       " 'crim',\n",
       " 'crocodile',\n",
       " 'crow',\n",
       " 'crown',\n",
       " 'crucible',\n",
       " 'crustacea',\n",
       " 'crystal',\n",
       " 'cuba',\n",
       " 'cubic',\n",
       " 'culpeper',\n",
       " 'cumberland',\n",
       " 'curdie',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'curtain',\n",
       " 'curve',\n",
       " 'cylinder',\n",
       " 'dance',\n",
       " 'dark',\n",
       " 'darkness',\n",
       " 'darling',\n",
       " 'date',\n",
       " 'dayroom',\n",
       " 'dead',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'december',\n",
       " 'declared',\n",
       " 'decoction',\n",
       " 'deep',\n",
       " 'deepsea',\n",
       " 'deer',\n",
       " 'definite',\n",
       " 'degree',\n",
       " 'delegate',\n",
       " 'demand',\n",
       " 'democracy',\n",
       " 'democratic',\n",
       " 'density',\n",
       " 'denísov',\n",
       " 'dephlogisticated',\n",
       " 'depth',\n",
       " 'deputy',\n",
       " 'dervish',\n",
       " 'described',\n",
       " 'descript',\n",
       " 'desert',\n",
       " 'detch',\n",
       " 'determination',\n",
       " 'development',\n",
       " 'dewdrop',\n",
       " 'diagram',\n",
       " 'diarrhea',\n",
       " 'dick',\n",
       " 'dickens',\n",
       " 'dickon',\n",
       " 'diddle',\n",
       " 'didn',\n",
       " 'died',\n",
       " 'diet',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficulty',\n",
       " 'diggingup',\n",
       " 'dilute',\n",
       " 'diminished',\n",
       " 'diminution',\n",
       " 'dinner',\n",
       " 'dioxide',\n",
       " 'discovery',\n",
       " 'disease',\n",
       " 'dish',\n",
       " 'dissolve',\n",
       " 'distilled',\n",
       " 'distinct',\n",
       " 'distribution',\n",
       " 'district',\n",
       " 'division',\n",
       " 'doctor',\n",
       " 'doctrine',\n",
       " 'doll',\n",
       " 'dollar',\n",
       " 'domestic',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'dorincourt',\n",
       " 'dormouse',\n",
       " 'dorothy',\n",
       " 'dose',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'dove',\n",
       " 'down',\n",
       " 'dram',\n",
       " 'drank',\n",
       " 'dressed',\n",
       " 'dried',\n",
       " 'driver',\n",
       " 'drone',\n",
       " 'drop',\n",
       " 'drug',\n",
       " 'drummond',\n",
       " 'duchess',\n",
       " 'duck',\n",
       " 'duke',\n",
       " 'dumpty',\n",
       " 'dunstable',\n",
       " 'duty',\n",
       " 'dynamo',\n",
       " 'earl',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eaten',\n",
       " 'economic',\n",
       " 'edible',\n",
       " 'edition',\n",
       " 'effect',\n",
       " 'eglentyne',\n",
       " 'egyptian',\n",
       " 'eighteen',\n",
       " 'election',\n",
       " 'electric',\n",
       " 'element',\n",
       " 'eleven',\n",
       " 'emerald',\n",
       " 'emerson',\n",
       " 'emil',\n",
       " 'emperor',\n",
       " 'empire',\n",
       " 'enemy',\n",
       " 'energy',\n",
       " 'engaged',\n",
       " 'engine',\n",
       " 'engineer',\n",
       " 'england',\n",
       " 'english',\n",
       " 'engs',\n",
       " 'enormous',\n",
       " 'enough',\n",
       " 'enrico',\n",
       " 'entirely',\n",
       " 'entrained',\n",
       " 'enzyme',\n",
       " 'equal',\n",
       " 'equilibrium',\n",
       " 'er',\n",
       " 'errol',\n",
       " 'essay',\n",
       " 'estate',\n",
       " 'ester',\n",
       " 'estimate',\n",
       " 'europe',\n",
       " 'european',\n",
       " 'eutectic',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'everything',\n",
       " 'evidence',\n",
       " 'evidently',\n",
       " 'evil',\n",
       " 'evolution',\n",
       " 'examination',\n",
       " 'examine',\n",
       " 'example',\n",
       " 'excess',\n",
       " 'executive',\n",
       " 'exercise',\n",
       " 'exist',\n",
       " 'existence',\n",
       " 'expedition',\n",
       " 'experiment',\n",
       " 'exposed',\n",
       " 'expression',\n",
       " 'external',\n",
       " 'extremity',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'fair',\n",
       " 'fairy',\n",
       " 'falkenstein',\n",
       " 'family',\n",
       " 'farm',\n",
       " 'farmer',\n",
       " 'farragut',\n",
       " 'farther',\n",
       " 'faster',\n",
       " 'fatal',\n",
       " 'father',\n",
       " 'fathom',\n",
       " 'fatter',\n",
       " 'fatty',\n",
       " 'fauna',\n",
       " 'fauntleroy',\n",
       " 'feather',\n",
       " 'february',\n",
       " 'fecl',\n",
       " 'federal',\n",
       " 'federalist',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'fence',\n",
       " 'fermentation',\n",
       " 'ferric',\n",
       " 'ferrous',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'fighting',\n",
       " 'figure',\n",
       " 'filled',\n",
       " 'filter',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finely',\n",
       " 'fire',\n",
       " 'firedrake',\n",
       " 'firefly',\n",
       " 'first',\n",
       " 'fish',\n",
       " 'fishbone',\n",
       " 'fixed',\n",
       " 'flag',\n",
       " 'flame',\n",
       " 'flanders',\n",
       " 'flask',\n",
       " 'flavour',\n",
       " 'fleet',\n",
       " 'flesh',\n",
       " 'flew',\n",
       " 'flour',\n",
       " 'flower',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'fond',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'footnote',\n",
       " 'force',\n",
       " 'foreign',\n",
       " 'forest',\n",
       " 'form',\n",
       " 'formation',\n",
       " 'formed',\n",
       " 'former',\n",
       " 'fort',\n",
       " 'forth',\n",
       " 'fossil',\n",
       " 'fought',\n",
       " 'found',\n",
       " 'france',\n",
       " 'frank',\n",
       " 'frederick',\n",
       " 'free',\n",
       " 'freezing',\n",
       " 'french',\n",
       " 'frequently',\n",
       " 'friend',\n",
       " 'frog',\n",
       " 'front',\n",
       " 'fruit',\n",
       " 'fruitarian',\n",
       " 'fuel',\n",
       " 'full',\n",
       " 'fume',\n",
       " 'function',\n",
       " 'furnace',\n",
       " 'fuse',\n",
       " 'fusion',\n",
       " 'game',\n",
       " 'garden',\n",
       " 'gauvain',\n",
       " 'gave',\n",
       " 'gelatin',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'generation',\n",
       " 'genius',\n",
       " 'gentleman',\n",
       " 'genus',\n",
       " 'german',\n",
       " 'germany',\n",
       " 'getting',\n",
       " 'giant',\n",
       " 'giglio',\n",
       " 'girl',\n",
       " 'girondin',\n",
       " 'give',\n",
       " 'given',\n",
       " 'glad',\n",
       " 'glass',\n",
       " 'globule',\n",
       " 'glory',\n",
       " 'gluckstein',\n",
       " 'glumboso',\n",
       " 'glycerine',\n",
       " 'glycerol',\n",
       " 'goblin',\n",
       " 'going',\n",
       " 'gold',\n",
       " 'goldfinch',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'goody',\n",
       " 'government',\n",
       " 'governor',\n",
       " 'grain',\n",
       " 'gram',\n",
       " 'gramme',\n",
       " 'grandfather',\n",
       " 'grandmarina',\n",
       " 'grandmother',\n",
       " 'grant',\n",
       " 'grass',\n",
       " 'gravel',\n",
       " 'gravity',\n",
       " 'gray',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'grew',\n",
       " 'grey',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'grouse',\n",
       " 'grow',\n",
       " 'grows',\n",
       " 'gruffanuff',\n",
       " 'gryphon',\n",
       " 'guard',\n",
       " 'gugu',\n",
       " 'guinea',\n",
       " 'habit',\n",
       " 'hackee',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hall',\n",
       " 'hamilton',\n",
       " 'hand',\n",
       " 'happened',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hardness',\n",
       " 'hare',\n",
       " 'hath',\n",
       " 'hatter',\n",
       " 'havisham',\n",
       " 'hcoh',\n",
       " 'head',\n",
       " 'health',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heated',\n",
       " 'heaven',\n",
       " 'heavy',\n",
       " 'hedzoff',\n",
       " 'held',\n",
       " 'helium',\n",
       " 'help',\n",
       " 'henry',\n",
       " 'herb',\n",
       " 'here',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highness',\n",
       " 'hill',\n",
       " 'hist',\n",
       " 'historian',\n",
       " 'historical',\n",
       " 'history',\n",
       " 'hobbs',\n",
       " 'hoch',\n",
       " 'hogginarmo',\n",
       " 'hold',\n",
       " 'hole',\n",
       " 'holiday',\n",
       " 'home',\n",
       " 'honey',\n",
       " 'honor',\n",
       " 'hook',\n",
       " 'hope',\n",
       " 'horn',\n",
       " 'horowitz',\n",
       " 'horrid',\n",
       " 'horse',\n",
       " 'hospital',\n",
       " 'hour',\n",
       " 'house',\n",
       " 'however',\n",
       " 'huck',\n",
       " 'hullo',\n",
       " 'human',\n",
       " 'humour',\n",
       " 'humpty',\n",
       " 'hundred',\n",
       " 'hungry',\n",
       " 'hurry',\n",
       " 'husband',\n",
       " 'hydrate',\n",
       " 'hydrochloric',\n",
       " 'hydrogen',\n",
       " 'hydrolysis',\n",
       " 'hydroxide',\n",
       " 'ibid',\n",
       " 'idea',\n",
       " 'ignition',\n",
       " 'illustration',\n",
       " 'immediately',\n",
       " 'imperial',\n",
       " 'implement',\n",
       " 'important',\n",
       " 'improvement',\n",
       " 'impulse',\n",
       " 'inca',\n",
       " 'inch',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'indeed',\n",
       " 'index',\n",
       " 'indian',\n",
       " 'indicator',\n",
       " 'individual',\n",
       " 'infantry',\n",
       " 'inflammable',\n",
       " 'inflammation',\n",
       " 'influence',\n",
       " 'infusible',\n",
       " 'inhabitant',\n",
       " 'injected',\n",
       " 'injection',\n",
       " 'inorganic',\n",
       " 'inside',\n",
       " 'instance',\n",
       " 'instinct',\n",
       " 'institution',\n",
       " 'interest',\n",
       " 'interesting',\n",
       " 'intestine',\n",
       " 'intoxication',\n",
       " 'invented',\n",
       " 'invention',\n",
       " 'investigation',\n",
       " 'iodine',\n",
       " 'ireland',\n",
       " 'irene',\n",
       " 'iron',\n",
       " 'isaac',\n",
       " 'island',\n",
       " 'isle',\n",
       " 'it',\n",
       " 'italy',\n",
       " 'its',\n",
       " 'ivar',\n",
       " 'jack',\n",
       " 'jackson',\n",
       " 'jacobin',\n",
       " 'james',\n",
       " 'january',\n",
       " 'jefferson',\n",
       " 'johann',\n",
       " 'john',\n",
       " 'johnny',\n",
       " 'johnston',\n",
       " 'joint',\n",
       " 'jones',\n",
       " 'joseph',\n",
       " 'journal',\n",
       " 'juice',\n",
       " 'julian',\n",
       " 'july',\n",
       " 'jumped',\n",
       " 'june',\n",
       " 'justice',\n",
       " 'keep',\n",
       " 'kennel',\n",
       " 'khan',\n",
       " 'kidney',\n",
       " 'kiki',\n",
       " 'killed',\n",
       " 'kilo',\n",
       " 'kind',\n",
       " 'king',\n",
       " 'kingdom',\n",
       " 'kiss',\n",
       " 'kitchen',\n",
       " 'kitten',\n",
       " 'kitty',\n",
       " 'knave',\n",
       " 'knew',\n",
       " 'knight',\n",
       " 'know',\n",
       " 'knowed',\n",
       " 'known',\n",
       " 'kutúzov',\n",
       " 'labour',\n",
       " 'lady',\n",
       " 'land',\n",
       " 'landwehr',\n",
       " 'language',\n",
       " 'large',\n",
       " 'last',\n",
       " 'later',\n",
       " 'latin',\n",
       " 'latter',\n",
       " 'laud',\n",
       " 'laughed',\n",
       " 'lavoisier',\n",
       " 'lawyer',\n",
       " 'lead',\n",
       " 'leader',\n",
       " 'leaf',\n",
       " 'least',\n",
       " 'lecithin',\n",
       " 'left',\n",
       " 'legend',\n",
       " 'legislature',\n",
       " 'lesson',\n",
       " 'letter',\n",
       " 'liaison',\n",
       " 'liberty',\n",
       " 'library',\n",
       " 'life',\n",
       " 'light',\n",
       " 'lightweight',\n",
       " 'limit',\n",
       " 'lindsay',\n",
       " 'line',\n",
       " 'linton',\n",
       " 'lion',\n",
       " 'liquid',\n",
       " 'liquor',\n",
       " 'listened',\n",
       " 'liter',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lived',\n",
       " 'liver',\n",
       " 'living',\n",
       " 'll',\n",
       " 'lobster',\n",
       " 'locomotive',\n",
       " 'london',\n",
       " 'lonesome',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'lookingglass',\n",
       " 'lootie',\n",
       " 'lord',\n",
       " 'lordship',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'louis',\n",
       " 'louisiana',\n",
       " 'love',\n",
       " 'lower',\n",
       " 'lung',\n",
       " 'lustre',\n",
       " 'machine',\n",
       " 'made',\n",
       " 'madison',\n",
       " 'maggie',\n",
       " 'magic',\n",
       " 'magician',\n",
       " 'magnesium',\n",
       " 'magnetic',\n",
       " 'majesty',\n",
       " 'majority',\n",
       " 'make',\n",
       " 'making',\n",
       " 'male',\n",
       " 'mamma',\n",
       " 'manganese',\n",
       " 'mankind',\n",
       " 'manner',\n",
       " 'many',\n",
       " 'march',\n",
       " 'marco',\n",
       " 'marie',\n",
       " 'marked',\n",
       " 'mars',\n",
       " 'martha',\n",
       " 'mary',\n",
       " 'mass',\n",
       " 'massachusetts',\n",
       " 'master',\n",
       " 'match',\n",
       " 'material',\n",
       " 'matter',\n",
       " 'maya',\n",
       " 'maybe',\n",
       " 'meal',\n",
       " 'mean',\n",
       " 'measure',\n",
       " 'meat',\n",
       " 'medical',\n",
       " 'medicine',\n",
       " 'medieval',\n",
       " 'medlock',\n",
       " 'melting',\n",
       " 'member',\n",
       " 'merchant',\n",
       " 'mercury',\n",
       " 'merit',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components=3)\n",
    "Book_topic=lsa.fit_transform(X)\n",
    "Sigma = lsa.singular_values_ \n",
    "V_transpose = lsa.components_.T\n",
    "lsa.components_\n",
    "terms = vectorizer.get_feature_names()\n",
    "lsa.components_\n",
    "for index, component in enumerate(lsa.components_):\n",
    "    zipped = zip(terms, component)\n",
    "    top_terms_key=sorted(zipped, key = lambda t: t[1], reverse=True)[:10]\n",
    "    top_terms_list=list(dict(top_terms_key).keys())\n",
    "    print(\"Topic \"+str(index)+\": \",top_terms_list)\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608ad29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice-in-wonderland  --Topic :  0\n",
      "Among the Forest People  --Topic :  0\n",
      "An Introductory Course of Quantitative Chemical Analysis  --Topic :  2\n",
      "Curious Myths of the Middle Ages  --Topic :  0\n",
      "Democracy In America, Volume 1 (of 2)  --Topic :  1\n",
      "Experiments and Observations on Different  --Topic :  2\n",
      "Formation of the Union, 1750-1829  --Topic :  1\n",
      "Histories of two hundred and fifty-one divisions of the German army which participated in the wa  --Topic :  1\n",
      "History of King Charles The First of England  --Topic :  0\n",
      "History of Phosphorus  --Topic :  2\n",
      "How the Flag Became Old Glory  --Topic :  1\n",
      "Little Lord Fauntleroy  --Topic :  0\n",
      "Medieval People  --Topic :  0\n",
      "Mother Storie  --Topic :  0\n",
      "Narrative and Critical History of America  --Topic :  1\n",
      "O Pioneers  --Topic :  0\n",
      "Peter-pan  --Topic :  0\n",
      "Prince Prigio  --Topic :  0\n",
      "Sandman_s Goodnight Stories  --Topic :  0\n",
      "The Chemistry of Cookery  --Topic :  2\n",
      "The Complete Herbal  --Topic :  2\n",
      "The Eighteenth Brumaire of Louis Bonaparte  --Topic :  1\n",
      "The Elements of Blowpipe Analysis  --Topic :  2\n",
      "The fauna of the deep sea  --Topic :  2\n",
      "The Foundations of the Origin of Species  --Topic :  1\n",
      "The French Revolution  --Topic :  0\n",
      "The Gases of the Atmosphere The History of Their Discovery by William Ramsay  --Topic :  2\n",
      "The Greater Republic  --Topic :  1\n",
      "The Handbook of Soap Manufacture  --Topic :  2\n",
      "The History of England from the Accession of James II  --Topic :  0\n",
      "The History Of The Decline And Fall Of The Roman Empire  --Topic :  1\n",
      "The Last Leaf  --Topic :  0\n",
      "The Magic Fishbone  --Topic :  0\n",
      "The Magic of Oz  --Topic :  0\n",
      "The Natural Food of Man  --Topic :  2\n",
      "The Phase Rule and Its Applications  --Topic :  2\n",
      "The Princess and the Goblin  --Topic :  0\n",
      "The Progress of Invention in the Nineteenth  --Topic :  1\n",
      "The Railway Children  --Topic :  0\n",
      "The Rose and the Ring  --Topic :  0\n",
      "The Ruins  --Topic :  0\n",
      "The Secret Garden  --Topic :  0\n",
      "The Tale of Timmy Tiptoes  --Topic :  0\n",
      "The Threefold Commonwealth  --Topic :  1\n",
      "The Toxicity of Caffein An experimental study on different species of animals  --Topic :  2\n",
      "The United States of America Part I  --Topic :  1\n",
      "The White Feather  --Topic :  0\n",
      "Three Minute Stories  --Topic :  0\n",
      "Through the Looking-Glass  --Topic :  0\n",
      "Tiger and Tom and Other Stories for Boys  --Topic :  0\n",
      "Tom Sawyer Abroad  --Topic :  0\n",
      "War and Peace  --Topic :  0\n"
     ]
    }
   ],
   "source": [
    "topic1=[]\n",
    "topic2=[]\n",
    "topic3=[]\n",
    "Book_topic2=lsa.transform(X)\n",
    "for n in range (Book_topic2.shape[0]):\n",
    "    topic_Book=Book_topic2[n].argmax()\n",
    "    if topic_Book==0:\n",
    "        topic1.append(listbook[n])\n",
    "    elif topic_Book==1:\n",
    "        topic2.append(listbook[n])\n",
    "    else:\n",
    "        topic3.append(listbook[n])\n",
    "        \n",
    "    \n",
    "    print(listbook[n],\" --Topic : \",topic_Book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca519d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.25080815e-01, -1.52869206e-01, -1.88789499e-02],\n",
       "       [ 5.64108257e-01, -2.29275127e-01,  4.03186781e-02],\n",
       "       [ 6.15815114e-02,  1.33951673e-01,  5.21340909e-01],\n",
       "       [ 4.10938041e-01,  1.66146540e-01,  3.75645768e-02],\n",
       "       [ 2.83178348e-01,  6.00665953e-01, -1.82556537e-01],\n",
       "       [ 1.55869470e-01,  2.02001849e-01,  4.43188888e-01],\n",
       "       [ 2.68221920e-01,  5.84071885e-01, -3.06156611e-01],\n",
       "       [ 3.39439516e-02,  4.07452469e-02, -8.23940692e-03],\n",
       "       [ 3.29174266e-01,  2.51388087e-01, -1.73991162e-01],\n",
       "       [ 8.95951147e-02,  1.71698500e-01,  3.49857624e-01],\n",
       "       [ 2.22866809e-01,  2.41845368e-01, -1.04936694e-01],\n",
       "       [ 4.48567445e-01, -1.97184257e-01,  1.05933689e-02],\n",
       "       [ 3.58259806e-01,  1.08474265e-01, -1.91511205e-02],\n",
       "       [ 5.70196469e-01, -2.60744960e-01,  3.52630293e-03],\n",
       "       [ 1.77793790e-01,  2.76163824e-01, -8.69936643e-03],\n",
       "       [ 3.44553559e-01, -1.02466299e-01, -7.29412805e-03],\n",
       "       [ 2.66048852e-01, -1.17088317e-01,  2.63319451e-03],\n",
       "       [ 3.83282103e-01, -1.42258975e-01, -6.05058633e-02],\n",
       "       [ 5.65221949e-01, -3.02658516e-01,  2.13592086e-02],\n",
       "       [ 1.67910856e-01,  2.00696755e-01,  5.83153449e-01],\n",
       "       [ 1.46051534e-01,  3.57060322e-02,  1.51866818e-01],\n",
       "       [ 1.66548298e-01,  3.14509914e-01, -1.26022972e-01],\n",
       "       [ 3.81949579e-02,  3.41678324e-02,  1.50771508e-01],\n",
       "       [ 1.11641878e-01,  1.37020511e-01,  2.59557661e-01],\n",
       "       [ 1.41313468e-01,  2.22325056e-01,  2.11061186e-01],\n",
       "       [ 3.76600646e-01,  1.48352463e-01, -5.77969631e-02],\n",
       "       [ 1.08920072e-01,  2.02840431e-01,  4.98337265e-01],\n",
       "       [ 3.16084671e-01,  5.06972061e-01, -2.08882035e-01],\n",
       "       [ 4.96465363e-02,  1.09358744e-01,  4.31151062e-01],\n",
       "       [ 4.25105513e-01,  3.94835037e-01, -1.52941911e-01],\n",
       "       [ 2.20020278e-01,  2.29301613e-01, -8.40060264e-02],\n",
       "       [ 5.28821794e-01,  6.36528355e-02, -2.73320086e-02],\n",
       "       [ 3.62457092e-01, -1.62864286e-01, -3.63115805e-02],\n",
       "       [ 3.02551641e-01, -9.04106923e-02,  1.15216997e-02],\n",
       "       [ 1.29341672e-01,  1.61774583e-01,  3.97946147e-01],\n",
       "       [ 7.07508500e-02,  1.36557858e-01,  3.41881404e-01],\n",
       "       [ 4.75079404e-01, -1.91119709e-01, -7.32194222e-03],\n",
       "       [ 1.73292673e-01,  1.95956664e-01,  1.12904336e-01],\n",
       "       [ 4.48967877e-01, -2.58656880e-01,  4.21253561e-04],\n",
       "       [ 3.56662599e-01, -1.35862420e-01, -6.07580925e-02],\n",
       "       [ 3.18301368e-01,  3.17786853e-01,  3.50738815e-02],\n",
       "       [ 4.38624788e-01, -2.25884091e-01, -2.20604751e-03],\n",
       "       [ 1.61729636e-01, -7.39153949e-02,  2.93412024e-02],\n",
       "       [ 1.78545378e-01,  1.92945845e-01,  6.11327429e-02],\n",
       "       [ 4.66225330e-02,  4.46581471e-02,  2.14084342e-01],\n",
       "       [ 3.05288418e-01,  6.07360805e-01, -2.62368255e-01],\n",
       "       [ 2.88357963e-01, -1.13803863e-01,  6.91614723e-03],\n",
       "       [ 5.80447524e-01, -2.93477856e-01,  2.68267593e-02],\n",
       "       [ 3.89436178e-01, -2.49093036e-01, -2.35473383e-02],\n",
       "       [ 6.49435472e-01, -2.20247450e-01,  1.20260957e-02],\n",
       "       [ 4.33007672e-01, -1.12921632e-01,  1.03052640e-02],\n",
       "       [ 4.53684925e-01, -1.34190847e-01, -6.11457515e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book_topic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2789145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 1 \n",
      " ['alice-in-wonderland', 'Among the Forest People', 'Curious Myths of the Middle Ages', 'History of King Charles The First of England', 'Little Lord Fauntleroy', 'Medieval People', 'Mother Storie', 'O Pioneers', 'Peter-pan', 'Prince Prigio', 'Sandman_s Goodnight Stories', 'The French Revolution', 'The History of England from the Accession of James II', 'The Last Leaf', 'The Magic Fishbone', 'The Magic of Oz', 'The Princess and the Goblin', 'The Railway Children', 'The Rose and the Ring', 'The Ruins', 'The Secret Garden', 'The Tale of Timmy Tiptoes', 'The White Feather', 'Three Minute Stories', 'Through the Looking-Glass', 'Tiger and Tom and Other Stories for Boys', 'Tom Sawyer Abroad', 'War and Peace'] \n",
      "\n",
      "topic 2 \n",
      " ['Democracy In America, Volume 1 (of 2)', 'Formation of the Union, 1750-1829', 'Histories of two hundred and fifty-one divisions of the German army which participated in the wa', 'How the Flag Became Old Glory', 'Narrative and Critical History of America', 'The Eighteenth Brumaire of Louis Bonaparte', 'The Foundations of the Origin of Species', 'The Greater Republic', 'The History Of The Decline And Fall Of The Roman Empire', 'The Progress of Invention in the Nineteenth', 'The Threefold Commonwealth', 'The United States of America Part I'] \n",
      "\n",
      "topic 3 \n",
      " ['An Introductory Course of Quantitative Chemical Analysis', 'Experiments and Observations on Different', 'History of Phosphorus', 'The Chemistry of Cookery', 'The Complete Herbal', 'The Elements of Blowpipe Analysis', 'The fauna of the deep sea', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Handbook of Soap Manufacture', 'The Natural Food of Man', 'The Phase Rule and Its Applications', 'The Toxicity of Caffein An experimental study on different species of animals'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"topic 1 \\n\" ,topic1,\"\\n\")\n",
    "print(\"topic 2 \\n\" ,topic2,\"\\n\")\n",
    "print(\"topic 3 \\n\" ,topic3,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825b5a9",
   "metadata": {},
   "source": [
    "# Ex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7abc4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_recommanded_book(book_name,nb_of_book):\n",
    "    essai=zip(listbook,Book_topic2)\n",
    "    indexation=[]\n",
    "    for n in range(len(listbook)):\n",
    "        indexation.append(n)\n",
    "\n",
    "    lect=zip(indexation,listbook)\n",
    "\n",
    "    Bookindex=\"\"\n",
    "    for key, value in lect:\n",
    "        if value==book_name:\n",
    "            Bookindex=key\n",
    "    print(book_name)\n",
    "\n",
    "    compare=[]\n",
    "    for n in range (Book_topic2.shape[0]):\n",
    "        compare.append(cosine_similarity([Book_topic2[Bookindex]], [Book_topic2[n]]))\n",
    "        \n",
    "    ordrebouquins=zip(indexation,compare)\n",
    "    Comparaison=np.sort(list(compare))\n",
    "\n",
    "    flattened = [val for sublist in Comparaison for val in sublist]\n",
    "    flattened2= [val for sublist in flattened for val in sublist]\n",
    "    listing=[]\n",
    "    for n in range(len(flattened2)):\n",
    "        listing.append([flattened2[n],n])\n",
    "\n",
    "\n",
    "    tel=sorted(listing,reverse=True)\n",
    "    n=nb_of_book\n",
    "    verif=tel[1:n+1]\n",
    "    \n",
    "    Booki=[]\n",
    "    for n in range(len(listbook)):\n",
    "        Booki.append([n,listbook[n]])\n",
    "        \n",
    "    cle=[]\n",
    "    for key,value in verif:\n",
    "        cle.append(value)\n",
    "    TestBook=[]\n",
    "    for n in range(len(Booki)):\n",
    "        Bookl=Booki[n]\n",
    "        for i in range(len(cle)):\n",
    "            if cle[i]==Bookl[0]:\n",
    "                TestBook.append(Bookl[1])\n",
    "    CloseBooks=sorted(TestBook,reverse=True)\n",
    "    print(CloseBooks,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b64e7125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histories of two hundred and fifty-one divisions of the German army which participated in the wa\n",
      "['The Ruins', 'The History of England from the Accession of James II', 'The History Of The Decline And Fall Of The Roman Empire', 'Narrative and Critical History of America', 'How the Flag Became Old Glory'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_recommanded_book(\"Histories of two hundred and fifty-one divisions of the German army which participated in the wa\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69063a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice-in-wonderland\n",
      "['Through the Looking-Glass', 'Three Minute Stories', 'The Secret Garden', 'The Railway Children', 'Sandman_s Goodnight Stories'] \n",
      "\n",
      "Among the Forest People\n",
      "['The White Feather', 'The Princess and the Goblin', 'Peter-pan', 'Mother Storie', 'Little Lord Fauntleroy'] \n",
      "\n",
      "An Introductory Course of Quantitative Chemical Analysis\n",
      "['The Toxicity of Caffein An experimental study on different species of animals', 'The Phase Rule and Its Applications', 'The Handbook of Soap Manufacture', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Elements of Blowpipe Analysis'] \n",
      "\n",
      "Curious Myths of the Middle Ages\n",
      "['The Threefold Commonwealth', 'The Ruins', 'The Last Leaf', 'The French Revolution', 'Medieval People'] \n",
      "\n",
      "Democracy In America, Volume 1 (of 2)\n",
      "['The United States of America Part I', 'The Greater Republic', 'The Eighteenth Brumaire of Louis Bonaparte', 'Narrative and Critical History of America', 'Formation of the Union, 1750-1829'] \n",
      "\n",
      "Experiments and Observations on Different\n",
      "['The fauna of the deep sea', 'The Natural Food of Man', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Chemistry of Cookery', 'History of Phosphorus'] \n",
      "\n",
      "Formation of the Union, 1750-1829\n",
      "['The United States of America Part I', 'The Greater Republic', 'The Eighteenth Brumaire of Louis Bonaparte', 'How the Flag Became Old Glory', 'Democracy In America, Volume 1 (of 2)'] \n",
      "\n",
      "Histories of two hundred and fifty-one divisions of the German army which participated in the wa\n",
      "['The Ruins', 'The History of England from the Accession of James II', 'The History Of The Decline And Fall Of The Roman Empire', 'Narrative and Critical History of America', 'How the Flag Became Old Glory'] \n",
      "\n",
      "History of King Charles The First of England\n",
      "['The History of England from the Accession of James II', 'The History Of The Decline And Fall Of The Roman Empire', 'The Greater Republic', 'The French Revolution', 'How the Flag Became Old Glory'] \n",
      "\n",
      "History of Phosphorus\n",
      "['The Phase Rule and Its Applications', 'The Natural Food of Man', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Chemistry of Cookery', 'Experiments and Observations on Different'] \n",
      "\n",
      "How the Flag Became Old Glory\n",
      "['The History of England from the Accession of James II', 'The History Of The Decline And Fall Of The Roman Empire', 'The Greater Republic', 'History of King Charles The First of England', 'Histories of two hundred and fifty-one divisions of the German army which participated in the wa'] \n",
      "\n",
      "Little Lord Fauntleroy\n",
      "['The White Feather', 'The Princess and the Goblin', 'Peter-pan', 'Mother Storie', 'Among the Forest People'] \n",
      "\n",
      "Medieval People\n",
      "['The Last Leaf', 'The History of England from the Accession of James II', 'The French Revolution', 'History of King Charles The First of England', 'Curious Myths of the Middle Ages'] \n",
      "\n",
      "Mother Storie\n",
      "['Three Minute Stories', 'The Secret Garden', 'The Princess and the Goblin', 'Peter-pan', 'Little Lord Fauntleroy'] \n",
      "\n",
      "Narrative and Critical History of America\n",
      "['The Threefold Commonwealth', 'The Ruins', 'The History Of The Decline And Fall Of The Roman Empire', 'Histories of two hundred and fifty-one divisions of the German army which participated in the wa', 'Democracy In America, Volume 1 (of 2)'] \n",
      "\n",
      "O Pioneers\n",
      "['Tom Sawyer Abroad', 'Tiger and Tom and Other Stories for Boys', 'The White Feather', 'The Princess and the Goblin', 'The Magic of Oz'] \n",
      "\n",
      "Peter-pan\n",
      "['Three Minute Stories', 'The Princess and the Goblin', 'Mother Storie', 'Little Lord Fauntleroy', 'Among the Forest People'] \n",
      "\n",
      "Prince Prigio\n",
      "['War and Peace', 'The White Feather', 'The Rose and the Ring', 'The Princess and the Goblin', 'The Magic Fishbone'] \n",
      "\n",
      "Sandman_s Goodnight Stories\n",
      "['Three Minute Stories', 'The Secret Garden', 'The Railway Children', 'Peter-pan', 'Mother Storie'] \n",
      "\n",
      "The Chemistry of Cookery\n",
      "['The Phase Rule and Its Applications', 'The Natural Food of Man', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Elements of Blowpipe Analysis', 'Experiments and Observations on Different'] \n",
      "\n",
      "The Complete Herbal\n",
      "['The fauna of the deep sea', 'The Natural Food of Man', 'The Elements of Blowpipe Analysis', 'The Chemistry of Cookery', 'Experiments and Observations on Different'] \n",
      "\n",
      "The Eighteenth Brumaire of Louis Bonaparte\n",
      "['The United States of America Part I', 'The Greater Republic', 'How the Flag Became Old Glory', 'Formation of the Union, 1750-1829', 'Democracy In America, Volume 1 (of 2)'] \n",
      "\n",
      "The Elements of Blowpipe Analysis\n",
      "['The Toxicity of Caffein An experimental study on different species of animals', 'The Phase Rule and Its Applications', 'The Handbook of Soap Manufacture', 'The Chemistry of Cookery', 'An Introductory Course of Quantitative Chemical Analysis'] \n",
      "\n",
      "The fauna of the deep sea\n",
      "['The Natural Food of Man', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Chemistry of Cookery', 'History of Phosphorus', 'Experiments and Observations on Different'] \n",
      "\n",
      "The Foundations of the Origin of Species\n",
      "['The fauna of the deep sea', 'The Progress of Invention in the Nineteenth', 'The Natural Food of Man', 'History of Phosphorus', 'Experiments and Observations on Different'] \n",
      "\n",
      "The French Revolution\n",
      "['The Last Leaf', 'The History of England from the Accession of James II', 'Medieval People', 'History of King Charles The First of England', 'Curious Myths of the Middle Ages'] \n",
      "\n",
      "The Gases of the Atmosphere The History of Their Discovery by William Ramsay\n",
      "['The Phase Rule and Its Applications', 'The Natural Food of Man', 'The Chemistry of Cookery', 'History of Phosphorus', 'Experiments and Observations on Different'] \n",
      "\n",
      "The Greater Republic\n",
      "['The United States of America Part I', 'The Eighteenth Brumaire of Louis Bonaparte', 'How the Flag Became Old Glory', 'Formation of the Union, 1750-1829', 'Democracy In America, Volume 1 (of 2)'] \n",
      "\n",
      "The Handbook of Soap Manufacture\n",
      "['The Toxicity of Caffein An experimental study on different species of animals', 'The Phase Rule and Its Applications', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Elements of Blowpipe Analysis', 'An Introductory Course of Quantitative Chemical Analysis'] \n",
      "\n",
      "The History of England from the Accession of James II\n",
      "['The History Of The Decline And Fall Of The Roman Empire', 'The Greater Republic', 'How the Flag Became Old Glory', 'History of King Charles The First of England', 'Histories of two hundred and fifty-one divisions of the German army which participated in the wa'] \n",
      "\n",
      "The History Of The Decline And Fall Of The Roman Empire\n",
      "['The History of England from the Accession of James II', 'The Greater Republic', 'How the Flag Became Old Glory', 'History of King Charles The First of England', 'Histories of two hundred and fifty-one divisions of the German army which participated in the wa'] \n",
      "\n",
      "The Last Leaf\n",
      "['War and Peace', 'Tom Sawyer Abroad', 'The French Revolution', 'Medieval People', 'Curious Myths of the Middle Ages'] \n",
      "\n",
      "The Magic Fishbone\n",
      "['The White Feather', 'The Secret Garden', 'The Rose and the Ring', 'The Princess and the Goblin', 'Mother Storie'] \n",
      "\n",
      "The Magic of Oz\n",
      "['Tom Sawyer Abroad', 'Tiger and Tom and Other Stories for Boys', 'The White Feather', 'O Pioneers', 'Among the Forest People'] \n",
      "\n",
      "The Natural Food of Man\n",
      "['The Phase Rule and Its Applications', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Chemistry of Cookery', 'History of Phosphorus', 'Experiments and Observations on Different'] \n",
      "\n",
      "The Phase Rule and Its Applications\n",
      "['The Natural Food of Man', 'The Gases of the Atmosphere The History of Their Discovery by William Ramsay', 'The Chemistry of Cookery', 'History of Phosphorus', 'An Introductory Course of Quantitative Chemical Analysis'] \n",
      "\n",
      "The Princess and the Goblin\n",
      "['Tiger and Tom and Other Stories for Boys', 'The White Feather', 'Peter-pan', 'Mother Storie', 'Little Lord Fauntleroy'] \n",
      "\n",
      "The Progress of Invention in the Nineteenth\n",
      "['The Threefold Commonwealth', 'The Ruins', 'The Foundations of the Origin of Species', 'Narrative and Critical History of America', 'Histories of two hundred and fifty-one divisions of the German army which participated in the wa'] \n",
      "\n",
      "The Railway Children\n",
      "['Through the Looking-Glass', 'Three Minute Stories', 'The Secret Garden', 'Sandman_s Goodnight Stories', 'Mother Storie'] \n",
      "\n",
      "The Rose and the Ring\n",
      "['War and Peace', 'The White Feather', 'The Princess and the Goblin', 'The Magic Fishbone', 'Prince Prigio'] \n",
      "\n",
      "The Ruins\n",
      "['The Threefold Commonwealth', 'The Progress of Invention in the Nineteenth', 'The History Of The Decline And Fall Of The Roman Empire', 'Narrative and Critical History of America', 'Histories of two hundred and fifty-one divisions of the German army which participated in the wa'] \n",
      "\n",
      "The Secret Garden\n",
      "['Three Minute Stories', 'The Railway Children', 'Sandman_s Goodnight Stories', 'Mother Storie', 'Little Lord Fauntleroy'] \n",
      "\n",
      "The Tale of Timmy Tiptoes\n",
      "['Three Minute Stories', 'Sandman_s Goodnight Stories', 'Peter-pan', 'Little Lord Fauntleroy', 'Among the Forest People'] \n",
      "\n",
      "The Threefold Commonwealth\n",
      "['The Ruins', 'The Progress of Invention in the Nineteenth', 'Narrative and Critical History of America', 'Histories of two hundred and fifty-one divisions of the German army which participated in the wa', 'Curious Myths of the Middle Ages'] \n",
      "\n",
      "The Toxicity of Caffein An experimental study on different species of animals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Phase Rule and Its Applications', 'The Handbook of Soap Manufacture', 'The Elements of Blowpipe Analysis', 'The Chemistry of Cookery', 'An Introductory Course of Quantitative Chemical Analysis'] \n",
      "\n",
      "The United States of America Part I\n",
      "['The Greater Republic', 'The Eighteenth Brumaire of Louis Bonaparte', 'How the Flag Became Old Glory', 'Formation of the Union, 1750-1829', 'Democracy In America, Volume 1 (of 2)'] \n",
      "\n",
      "The White Feather\n",
      "['Tiger and Tom and Other Stories for Boys', 'The Princess and the Goblin', 'Peter-pan', 'Mother Storie', 'Little Lord Fauntleroy'] \n",
      "\n",
      "Three Minute Stories\n",
      "['The Secret Garden', 'Sandman_s Goodnight Stories', 'Peter-pan', 'Mother Storie', 'Little Lord Fauntleroy'] \n",
      "\n",
      "Through the Looking-Glass\n",
      "['alice-in-wonderland', 'Three Minute Stories', 'The Secret Garden', 'The Railway Children', 'Sandman_s Goodnight Stories'] \n",
      "\n",
      "Tiger and Tom and Other Stories for Boys\n",
      "['Tom Sawyer Abroad', 'The White Feather', 'The Princess and the Goblin', 'The Magic of Oz', 'O Pioneers'] \n",
      "\n",
      "Tom Sawyer Abroad\n",
      "['Tiger and Tom and Other Stories for Boys', 'The White Feather', 'The Princess and the Goblin', 'The Magic of Oz', 'O Pioneers'] \n",
      "\n",
      "War and Peace\n",
      "['Tiger and Tom and Other Stories for Boys', 'The Rose and the Ring', 'The Magic Fishbone', 'Prince Prigio', 'O Pioneers'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for book in booklists:\n",
    "    cleanbook=book.replace(\".txt\",\"\")\n",
    "    best_recommanded_book(cleanbook,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
